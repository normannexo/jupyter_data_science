{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Tip**: Welcome to the Investigate a Dataset project! You will find tips in quoted sections like this to help organize your approach to your investigation. Before submitting your project, it will be a good idea to go back through your report and remove these sections to make the presentation of your work as tidy as possible. First things first, you might want to double-click this Markdown cell and change the title so that it reflects your dataset and investigation.\n",
    "\n",
    "# Investigation of Kaggle's soccer database\n",
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "<li><a href=\"#wrangling\">Data Wrangling</a></li>\n",
    "<li><a href=\"#eda\">Exploratory Data Analysis</a></li>\n",
    "<li><a href=\"#conclusions\">Conclusions</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "> **Tip**: In this section of the report, provide a brief introduction to the dataset you've selected for analysis. At the end of this section, describe the questions that you plan on exploring over the course of the report. Try to build your report around the analysis of at least one dependent variable and three independent variables.\n",
    ">\n",
    "> If you haven't yet selected and downloaded your data, make sure you do that first before coming back here. If you're not sure what questions to ask right now, then make sure you familiarize yourself with the variables and the dataset context for ideas of what to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlalchemy as sqla\n",
    "import xml.etree.ElementTree as ET\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wrangling'></a>\n",
    "## Data Wrangling\n",
    "\n",
    "> **Tip**: In this section of the report, you will load in the data, check for cleanliness, and then trim and clean your dataset for analysis. Make sure that you document your steps carefully and justify your cleaning decisions.\n",
    "\n",
    "### General Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   match_id                    name     season\n",
      "0      1729  England Premier League  2008/2009\n",
      "1      1730  England Premier League  2008/2009\n",
      "2      1731  England Premier League  2008/2009\n",
      "   id  player_api_id         player_name  player_fifa_api_id  \\\n",
      "0   1         505942  Aaron Appindangoye              218353   \n",
      "1   2         155782     Aaron Cresswell              189615   \n",
      "2   3         162549         Aaron Doran              186170   \n",
      "3   4          30572       Aaron Galindo              140161   \n",
      "4   5          23780        Aaron Hughes               17725   \n",
      "\n",
      "              birthday  height  weight  \n",
      "0  1992-02-29 00:00:00  182.88     187  \n",
      "1  1989-12-15 00:00:00  170.18     146  \n",
      "2  1991-05-13 00:00:00  170.18     163  \n",
      "3  1982-05-08 00:00:00  182.88     198  \n",
      "4  1979-11-08 00:00:00  182.88     154  \n",
      "match_id           int64\n",
      "name              object\n",
      "season            object\n",
      "possession        object\n",
      "home_team_goal     int64\n",
      "away_team_goal     int64\n",
      "shoton            object\n",
      "shotoff           object\n",
      "dtype: object\n",
      "id                      int64\n",
      "player_api_id           int64\n",
      "player_name            object\n",
      "player_fifa_api_id      int64\n",
      "birthday               object\n",
      "height                float64\n",
      "weight                  int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load your data and print out a few lines. Perform operations to inspect data\n",
    "#   types and look for instances of missing or possibly errant data.\n",
    "# build sql query to extract match data - ignore data without valid possession data\n",
    "query_match = \"\"\"select match.id as match_id, league.name, season, possession, home_team_goal, away_team_goal, shoton, shotoff\n",
    "from Match inner join league on match.league_id = league.id\n",
    "where league_id = 1729\n",
    " \"\"\"\n",
    "query_player = \"\"\"\n",
    "select * from player;\n",
    " \"\"\"\n",
    "db = sqla.create_engine('sqlite:///data/database.sqlite')\n",
    "df_match = pd.read_sql(query_match, db)\n",
    "df_player = pd.read_sql(query_player,db)\n",
    "print(df_match.iloc[:3,:3])\n",
    "print(df_player.head())\n",
    "print(df_match.dtypes)\n",
    "print(df_player.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Tip**: You should _not_ perform too many operations in each cell. Create cells freely to explore your data. One option that you can take with this project is to do a lot of explorations in an initial notebook. These don't have to be organized, but make sure you use enough comments to understand the purpose of each code cell. Then, after you're done with your analysis, create a duplicate notebook where you will trim the excess and organize your steps so that you have a flowing, cohesive report.\n",
    "\n",
    "> **Tip**: Make sure that you keep your reader informed on the steps that you are taking in your investigation. Follow every code cell, or every set of related code cells, with a markdown cell to describe to the reader what was found in the preceding cell(s). Try to make it so that the reader can then understand what they will be seeing in the following cell(s).\n",
    "\n",
    "### Data Cleaning\n",
    "First defining some helper functions, see the comments in the line above the definition to learn about their specific tasks\n",
    "```\n",
    "def flatten(list_of_list)\n",
    "\n",
    "def build_possession_row_from_xml(xmlstring, matchid)\n",
    "\n",
    "def build_shotlists_from_xml(xmlstring, matchid)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function flatten, flattening of lists. occassionally we have to deal with lists of lists\n",
    "#which have to be flattened to be used in data frames.\n",
    "def flatten(list_of_list):\n",
    "    flattened_list = [y for x in list_of_list for y in x]\n",
    "    return flattened_list\n",
    "\n",
    "# Helper function to extract xml data from the column possession of data frame df_match\n",
    "def build_possession_row_from_xml(xmlstring, matchid):\n",
    "    root = ET.fromstring(xmlstring)\n",
    "    # we are interested in the last entry only, usually the possession values after 90 minutes\n",
    "    tags = root.findall(\"value[last()]\")\n",
    "\n",
    "    rows = []\n",
    "    #there should be only one tag found, but leaving loop for possible later changes\n",
    "    for node in tags:\n",
    "        #print(node)\n",
    "        elapsed = node.findtext(\"elapsed\") if node is not None else None\n",
    "        homepos = node.findtext(\"homepos\") if node is not None else None\n",
    "        \n",
    "        awaypos = node.findtext(\"awaypos\") if node is not None else None\n",
    "        rows.append({\"match_id\": matchid, \"elapsed\": elapsed, \"homepos\": homepos, \n",
    "                     \"awaypos\": awaypos})\n",
    "    if rows.count == 0:\n",
    "        return  None\n",
    "    else:\n",
    "        #return value is a list of dictionaries\n",
    "        return rows\n",
    "\n",
    "# Helper function to extract xml data from the columns shotson and shotsoff of df_match\n",
    "def build_shotlists_from_xml(xmlstring, matchid):\n",
    "    root = ET.fromstring(xmlstring)\n",
    "   \n",
    "    rows = []\n",
    "    for node in root: \n",
    "        elapsed = node.findtext(\"elapsed\") if node is not None else None\n",
    "        team = node.findtext(\"team\") if node is not None else None\n",
    "        type_s = node.findtext(\"type\") if node is not None else None\n",
    "        player = node.findtext(\"player1\") if node is not None else None\n",
    "        rows.append({\"match_id\": matchid, \"elapsed\": elapsed, \"team\": team, \"player\": player,\n",
    "                     \"type\": type_s})\n",
    "    if rows.count == 0:\n",
    "        return  None\n",
    "    else:\n",
    "        return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **create additional data frames**  \n",
    "Creating some extra data frames from xml content of some columns of the `df_match` data frame with the code of next cells.  \n",
    "These data frames are needed later for further analysis.\n",
    "\n",
    "#### Create data frame `df_pos` for possession data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   match_id elapsed homepos awaypos\n",
      "0      1729      90      55      45\n",
      "1      1730      90      66      34\n",
      "2      1731      90      46      54\n",
      "3      1732      90      52      48\n",
      "match_id     int64\n",
      "elapsed     object\n",
      "homepos     object\n",
      "awaypos     object\n",
      "dtype: object\n",
      "match_id    0\n",
      "elapsed     0\n",
      "homepos     1\n",
      "awaypos     1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# parse xml data of column possession with helper funcion\n",
    "rows_pos = df_match.apply(lambda x : build_possession_row_from_xml(x['possession'], x['match_id']), axis=1)\n",
    "flattened_list = flatten(rows_pos.values.tolist())\n",
    "\n",
    "# build new data frame with possession data and show a few lines and data types\n",
    "df_pos = pd.DataFrame(flattened_list)\n",
    "print(df_pos.loc[:3])\n",
    "print(df_pos.dtypes)\n",
    "# show possible NaN values\n",
    "print(df_pos.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### comment\n",
    "> 3 columns of new data frame `df_pos` are all strings because of the previous xml parsing.  \n",
    "So, casting columns to ints. *homepos, awaypos* both have NaNs in certain rows. We have to drop affected rows first.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "match_id    int64\n",
       "elapsed     int64\n",
       "homepos     int64\n",
       "awaypos     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get rid of rows with NaNs in homepos or awaypos\n",
    "df_pos.dropna(subset=['homepos','awaypos'], inplace=True)\n",
    "# set all columns to int64 and check with dtype\n",
    "df_pos = df_pos.astype('int64')\n",
    "df_pos.dtypes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create data frame `df_shots` from shotson and shotsoff data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "match_id      int64\n",
       "elapsed      object\n",
       "team         object\n",
       "player      float64\n",
       "type         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_on = df_match.apply(lambda x : build_shotlists_from_xml(x['shoton'], x['match_id']), axis=1)\n",
    "df_shoton = pd.DataFrame(flatten(rows_on.values.tolist()))\n",
    "rows_off = df_match.apply(lambda x : build_shotlists_from_xml(x['shotoff'], x['match_id']), axis=1)\n",
    "df_shotoff = pd.DataFrame(flatten(rows_off.values.tolist()))\n",
    "df_shots = pd.concat([df_shotoff, df_shoton])\n",
    "df_shots[df_shots['match_id']==1729].sort_values(by=['elapsed'])\n",
    "df_shots['player'] = pd.to_numeric(df_shots['player'], downcast='integer', errors='coerce')\n",
    "#df_shots['player'] = df_shots[df_shots['player'].notnull()]['player'].astype('int64')\n",
    "df_shots.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "player_name\n",
       "Franck Jurietti            7\n",
       "Tugay Kerimoglou          59\n",
       "Ricky van Wolfswinkel     63\n",
       "Dudu                      70\n",
       "Franco Di Santo          189\n",
       "Ricardo Oliveira         227\n",
       "dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df_player.merge(df_shots, left_on=('id'), right_on=('player'))\n",
    "result.groupby('player_name').size().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'></a>\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "> **Tip**: Now that you've trimmed and cleaned your data, you're ready to move on to exploration. Compute statistics and create visualizations with the goal of addressing the research questions that you posed in the Introduction section. It is recommended that you be systematic with your approach. Look at one variable at a time, and then follow it up by looking at relationships between variables.\n",
    "\n",
    "### Research Question 1 (Replace this header name!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Use this, and more code cells, to explore your data. Don't forget to add\n",
    "#   Markdown cells to document your observations and findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Question 2  (Replace this header name!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Continue to explore the data to address your additional research\n",
    "#   questions. Add more headers as needed if you have more questions to\n",
    "#   investigate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## Conclusions\n",
    "\n",
    "> **Tip**: Finally, summarize your findings and the results that have been performed. Make sure that you are clear with regards to the limitations of your exploration. If you haven't done any statistical tests, do not imply any statistical conclusions. And make sure you avoid implying causation from correlation!\n",
    "\n",
    "> **Tip**: Once you are satisfied with your work, you should save a copy of the report in HTML or PDF form via the **File** > **Download as** submenu. Before exporting your report, check over it to make sure that the flow of the report is complete. You should probably remove all of the \"Tip\" quotes like this one so that the presentation is as tidy as possible. Congratulations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
